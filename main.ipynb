{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDIM Inversion\n",
    "\n",
    "Notebook written by **Jordan Lin** for CS 188 project.\n",
    "\n",
    "`main.ipynb` is an alternative to `main.py` where I have more flexibility to experiment with my code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False  # True if we are training, False otherwise\n",
    "yaml_path = \"./configs/flowers102.yml\"  # Config path for if train = True\n",
    "log_path = \"./logs/run_230226_031528\"  # Model load path for if train = False\n",
    "\n",
    "gpu_num = 0  # For multiple-GPU training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External files edited elsewhere (e.g., PyCharm) are reloaded in Jupyter Notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from functools import partial\n",
    "\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from networks.unet import UNet\n",
    "from runners.diffusion import Diffusion\n",
    "\n",
    "import inversions.optimization as oinv\n",
    "import inversions.learning as linv\n",
    "import inversions.hybrid as hinv\n",
    "import inversions.interpolation as iinv\n",
    "\n",
    "import utilities.data as dutils\n",
    "import utilities.math as mutils\n",
    "import utilities.network as nutils\n",
    "import utilities.runner as rutils\n",
    "import utilities.utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{gpu_num}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_torch_image(image, norm=(0, 1)):\n",
    "    if len(image.shape) == 4:\n",
    "        image = image[0]\n",
    "    if norm is None:\n",
    "        norm = (image.min(), image.max())\n",
    "    image = (image - norm[0]) / (norm[1] - norm[0])\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.moveaxis(-3, -1).detach().cpu().numpy(), vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    config = utils.get_yaml(path=yaml_path)\n",
    "else:\n",
    "    config = utils.get_yaml(path=f\"{log_path}/config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = Diffusion(config, device=device)\n",
    "print(f\"Number of parameters: {diffusion.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=logs --port=8008 --load_fast=false --samples_per_plugin images=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    diffusion.train()\n",
    "else:\n",
    "    diffusion.load(path=f\"{log_path}/network_{config.training.num_i}.pth\", ema=False)\n",
    "    diffusion.load(path=f\"{log_path}/ema_{config.training.num_i}.pth\", ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion.freeze(ema=False)  # Freeze model layers to prevent OOM error during naive inversion\n",
    "diffusion.freeze(ema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = dutils.get_dataset(name=config.data.dataset, shape=config.data.shape,\n",
    "                                   root=config.data.root, split=\"valid\",\n",
    "                                   download=config.data.download)\n",
    "valid_loader = data.DataLoader(valid_dataset, batch_size=config.training.batch_size,\n",
    "                               shuffle=True, num_workers=config.data.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_1 = next(iter(valid_loader))[0][0]\n",
    "test_image_2 = next(iter(valid_loader))[0][0]\n",
    "display_torch_image(test_image_1)\n",
    "display_torch_image(test_image_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_1 = torch.randn(*test_image_1.shape, device=device)\n",
    "z_2 = torch.randn(*test_image_2.shape, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_torch_video(images, path, interval=50, scale=1):\n",
    "    images = [image.moveaxis(0, -1).numpy() for image in images]\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    axes = plt.Axes(figure, [0.0, 0.0, 1.0, 1.0])\n",
    "    axes.set_axis_off()\n",
    "    figure.add_axes(axes)\n",
    "    figure.set_size_inches(images[0].shape[0] / 100 * scale, images[0].shape[1] / 100 * scale)\n",
    "    \n",
    "    frames = []\n",
    "    for image in images:\n",
    "        frames.append([axes.imshow(image, animated=True, aspect=1)])\n",
    "        \n",
    "    animation_ = animation.ArtistAnimation(figure, frames, interval=50)\n",
    "    animation_.save(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mixes = iinv.proj_interpolation(z_1.clone(), z_2.clone(), diffusion=diffusion,\n",
    "                                  proj_fn_1=None, proj_fn_2=None,\n",
    "                                  num_t_steps=10, num_alphas=100, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_torch_video(x_mixes, path=\"results/test4.mp4\", scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_fn_1 = partial(oinv.gradient_inversion, target=test_image_1, diffusion=diffusion, lr=0.02,\n",
    "                    num_i=300, criterion=\"psnr\", show_progress=True)\n",
    "proj_fn_2 = partial(oinv.gradient_inversion, target=test_image_2, diffusion=diffusion, lr=0.02,\n",
    "                    num_i=300, criterion=\"psnr\", show_progress=True)\n",
    "\n",
    "x_mixes = iinv.proj_interpolation(z_1.clone(), z_2.clone(), diffusion=diffusion,\n",
    "                                  proj_fn_1=proj_fn_1, proj_fn_2=proj_fn_2,\n",
    "                                  num_t_steps=10, num_alphas=100, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_torch_video(x_mixes, path=\"results/test5.mp4\", scale=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "transform = transforms.Compose([transforms.CenterCrop((256, 256)), transforms.ToTensor()])\n",
    "\n",
    "lsun_data = datasets.LSUN(root=config.data.root, classes=[\"church_outdoor_train\"], transform=transform)\n",
    "lsun_loader = data.DataLoader(lsun_data, batch_size=config.training.batch_size,\n",
    "                              shuffle=True, num_workers=config.data.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsun_image = next(iter(lsun_loader))[0][0]\n",
    "print(lsun_image.shape)\n",
    "display_torch_image(lsun_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image, label in tqdm(iter(lsun_loader)):\n",
    "    i += image.shape[0]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data = dutils.get_dataset(name=\"miniplaces\", shape=(128, 128),\n",
    "                               root=config.data.root, split=\"train\")\n",
    "mini_loader = data.DataLoader(mini_data, batch_size=config.training.batch_size,\n",
    "                              shuffle=True, num_workers=config.data.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_image = next(iter(mini_loader))[0][0]\n",
    "print(mini_image.shape)\n",
    "display_torch_image(mini_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image, label in tqdm(iter(mini_loader)):\n",
    "    i += image.shape[0]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
